# Ollama

Ollama позволяет запускать текстовые нейромодели локально. 

## Установка в Docker

```
docker pull ollama/ollama

# Запуск на CPU
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

# Запуск на GPU
docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

# Запустить модель
docker exec -it ollama ollama run модель

# Или так, имея доступ к оболочке
docker exec -it ollama bin/bash
ollama run модель
```

Загрузить модели можно [отсюда](https://ollama.com/library).

При загрузке моделей нужно обращать внимание на параметры. Обычно указывается число и буква B. Например 3B, 1.5B.

Для работы моделей 7B вам потребуется не менее 8 ГБ оперативной памяти, для работы моделей 13B — 16 ГБ, а для работы моделей 33B — 32 ГБ.


## Кастомизация ответов

Есть возможность кастомизировать ответы нейросети. Например, сделать так, чтобы она отвечала как персонаж из мультика или герой фильма или игры. Для этого нужно создать файл без расширения Modelfile.

```
docker exec -it ollama bin/bash
touch Modelfile
```

Далее нужно открыть Modelfile и вписать туда примерно следующее - это простой вариант использования.

```
FROM названиеМодели
PARAMETER temperature 1
SYSTEM "Запрос. Например - ты выполняешь роль преподавателя."
```

Дальше нужно создать и запустить созданную модель.

```
ollama create имяДляНовойМодели -f Modelfile
ollama run имяДляНовойМодели
```


## API

Так же есть возможность использовать Ollama при помощи языков программирования, например Python. Убедитесь, что у вас установлен интерпретатор языка. Если используете Docker, убедитесь, что интерпретатор установлен в контейнере или установите его.

Далее будет предоставлен простой пример. По сути все сводится к отправлению POST запроса и парсингу выходного json, к которому придется обратиться.

```python
import requests
import json
url="http://localhost:11434/api/generate"
headers={"content-type":"application/json"}
data={
"model":"модель",
"prompt":"запрос",
"stream":False
}
response=requests.post(url,headers=headers,data=json.dumps(data))
if response.status_code==200:
	response_text=response.text
	data=json.loads(response_text)
	actual_response=data["response"]
	print(actual_response)
else:
	print("Ошибка")
```

data содержит словарь. В примере выше было обращение к ключу response, чтобы получить содержимое ответа. Можно получить весь словарь, если принтовать его без ключей. Ниже будет описание полученных ключей.


| Ключ                     | Описание                                                                          |
| ------------------------ | --------------------------------------------------------------------------------- |
| **total_duration**       | Время потраченное на генерацию ответа                                             |
| **load_duration**        | Время затраченное на загрузку модели в наносекундах                               |
| **prompt_eval_count**    | Количество токенов в запросе                                                      |
| **prompt_eval_duration** | Время оценки запроса в наносекундах                                               |
| **eval_count**           | Количество токенов в ответе                                                       |
| **eval_duration**        | Время в наносекундах для генерации ответа                                         |
| **context**              | Контекст. Его можно вставить в кастомизацию для возможности продолжения разговора |
| **response**             | Ответ                                                                             |

### Перечень некоторых ключей для data-запроса


| Ключ           | Описание                                                                                                                                                                                                                                               |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **model**      | Модель                                                                                                                                                                                                                                                 |
| **prompt**     | Промпт                                                                                                                                                                                                                                                 |
| **message**    | более расширенный вариант создания промпта. В качестве значения принимает список с вложенным словарем. Далее будут перечислены ключи для этого вложенного словаря.<br>role - роль. Значением может быть user, assistant или tool.<br>content - промпт. |
| **stream**     | Если значение True, то ответ будет выдаваться потоком как в ChatGPT. Если False - ответ будет выдаваться сразу, что более предпочтительно при работе с API.                                                                                            |
| **keep_alive** | Продолжительность хранения модели в памяти. По умолчанию 5m. Если 0 - модель будет выгружена из памяти                                                                                                                                                 |
| **options**    | Дополнительные настройки, которые будут рассмотрены ниже. Принимаются некоторые параметры, что и при создании Modelfile.                                                                                                                               |

## Modelfile

В этом разделе будет подробная информация о содержимом Modelfile. Общая схема инструкций выглядит следующим образом:

```
# комментарий
ИНСТРУКЦИЯ аргументы
```


| Инструкция         | Описание и применение                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| FROM               | Базовая модель. Сюда передается модель, на основе которой будет генерация<br><br>Базовый пример<br>FROM имяМодели:тег<br><br>Для загрузки safetensors моделей<br>FROM путьКМодели                                                                                                                                                                                                                                                                                                                          |
| PARAMETER <br><br> | Параметры, с которыми будет запускаться модель<br><br>Пример<br>PARAMETER параметр значение<br><br>Некоторые параметры<br>temperature - чем выше значение тем креативнее ответ. Есть риск фантазирования при повышении значения. По умолчанию 0.8<br>seed - сид. Если явно установлен, при повторной генерации будет точно такой же ответ<br>top_k - вероятность бессмыслицы. По умолчанию 40<br>top_p - разнообразие в тексте. Более низкие значения делают ответ более сфокусированным. По умолчанию 0.9 |
| MESSAGE            | Позволяет передать историю сообщений пользователя и собеседника, чтобы нейросеть обучилась как отвечать пользователю. Свойство system является альтернативой SYSTEM. user - сообщение пользователя.  assistant - сообщение нейросети. <br><br>Пример запроса<br><br>MESSAGE user Сообщение<br>MESSAGE assistant Сщщбщение<br>...                                                                                                                                                                           |
|                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
|                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |









